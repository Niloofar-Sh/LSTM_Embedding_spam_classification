{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5a03f96",
   "metadata": {},
   "source": [
    "## Loading Spam Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8677e812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded Data :\n",
      "------------------------------------\n",
      "  CLASS                                                SMS\n",
      "0   ham   said kiss, kiss, i can't do the sound effects...\n",
      "1   ham      &lt;#&gt; ISH MINUTES WAS 5 MINUTES AGO. WTF.\n",
      "2  spam  (Bank of Granite issues Strong-Buy) EXPLOSIVE ...\n",
      "3  spam  * FREE* POLYPHONIC RINGTONE Text SUPER to 8713...\n",
      "4  spam  **FREE MESSAGE**Thanks for using the Auction S...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "#Load Spam Data and review content\n",
    "spam_data = pd.read_csv(\"Spam-Classification.csv\")\n",
    "\n",
    "print(\"\\nLoaded Data :\\n------------------------------------\")\n",
    "print(spam_data.head())\n",
    "\n",
    "#Separate feature and target data\n",
    "spam_classes_txt = spam_data[\"CLASS\"]\n",
    "spam_messages = spam_data[\"SMS\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ea2628",
   "metadata": {},
   "source": [
    "##  Preprocessing Spam Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ed58ecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-hot Encoding Shape :  (1500, 2)\n"
     ]
    }
   ],
   "source": [
    "#Build a label encoder for target variable to convert strings to numeric values.\n",
    "from sklearn import preprocessing\n",
    "import tensorflow as tf\n",
    "\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "spam_classes_binary = label_encoder.fit_transform(\n",
    "                                spam_classes_txt)\n",
    "\n",
    "#Convert target to one-hot encoding vector\n",
    "spam_classes_one_hot = tf.keras.utils.to_categorical(spam_classes_binary,2)\n",
    "\n",
    "print(\"One-hot Encoding Shape : \", spam_classes_one_hot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c82d032",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, ..., 0, 0, 1])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_classes_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "451dfb84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       ...,\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_classes_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba80c64a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique tokens found:  4688\n",
      "Example token ID for word \"kiss\" : 921\n",
      "\n",
      "Total sequences found :  1500\n",
      "Example Sequence for sentence :   said kiss, kiss, i can't do the sound effects! He is a gorgeous man isn't he! Kind of person who needs a smile to brighten his day! \n",
      "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0  260  921  921    4  430   55    6 1488 2294  148   10\n",
      "    3 1489  464 1143  148  922   19  514   77 1144    3  515    1 2295\n",
      "  397   89]\n"
     ]
    }
   ],
   "source": [
    "#Preprocess data for spam messages\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "#Max words in the vocabulary for this dataset\n",
    "VOCAB_WORDS=10000\n",
    "#Max sequence length for word sequences\n",
    "MAX_SEQUENCE_LENGTH=100\n",
    "\n",
    "#Create a vocabulary with unique words and IDs\n",
    "spam_tokenizer = Tokenizer(num_words=VOCAB_WORDS)\n",
    "spam_tokenizer.fit_on_texts(spam_messages)\n",
    "\n",
    "\n",
    "print(\"Total unique tokens found: \", len(spam_tokenizer.word_index))\n",
    "print(\"Example token ID for word \\\"kiss\\\" :\", spam_tokenizer.word_index.get(\"kiss\"))\n",
    "\n",
    "#Convert sentences to token-ID sequences\n",
    "spam_sequences = spam_tokenizer.texts_to_sequences(spam_messages)\n",
    "\n",
    "#Pad all sequences to fixed length\n",
    "spam_padded = pad_sequences(spam_sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "print(\"\\nTotal sequences found : \", len(spam_padded))\n",
    "print(\"Example Sequence for sentence : \", spam_messages[0] )\n",
    "print(spam_padded[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de77ac7",
   "metadata": {},
   "source": [
    "## Split into training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d4d02b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "                                    spam_padded,spam_classes_one_hot,test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a86202c",
   "metadata": {},
   "source": [
    "## Building the embeddding matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e8d1cb80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary Size:  400000\n"
     ]
    }
   ],
   "source": [
    "#Load the pre-trained embeddings\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "#Read pretrained embeddings into a dictionary\n",
    "glove_dict = {} \n",
    "\n",
    "#Loading a 50 feature (dimension) embedding with 6 billion words\n",
    "with open('glove.6B.50d.txt', \"r\", encoding=\"utf8\") as glove_file:     \n",
    "    for line in glove_file:\n",
    "        \n",
    "        emb_line = line.split()      \n",
    "        emb_token = emb_line[0]         \n",
    "        emb_vector = np.array(emb_line[1:], dtype=np.float32)\n",
    "        \n",
    "        if emb_vector.shape[0] == 50:    \n",
    "            glove_dict[emb_token] = emb_vector \n",
    "print(\"Dictionary Size: \", len(glove_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6c5b4b",
   "metadata": {},
   "source": [
    "## Test the entry for the word \"sky\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "66da8d8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Sample Dictionary Entry for word \"sky\" :\n",
      " [ 0.081092   0.94466    0.33658    0.42124    0.27977   -0.73385\n",
      " -0.97879   -0.52544    0.13249   -0.2126     0.41312    0.19676\n",
      "  0.12114    0.87748   -0.16792    0.79765   -0.18026    0.23597\n",
      " -1.9492    -0.84402    0.15311    1.0843     0.52439   -0.28308\n",
      "  0.17648   -0.37219   -0.68172    1.4701     0.48146    0.028964\n",
      "  1.9263     0.55726    0.092331  -0.2266    -0.41086   -0.23616\n",
      " -0.12419   -1.0425    -0.22734   -0.58257    0.58536    0.20313\n",
      " -0.2065    -0.41059   -0.39159    0.12677    0.10595   -0.52283\n",
      " -0.0062389 -0.56913  ]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n Sample Dictionary Entry for word \\\"sky\\\" :\\n\", glove_dict.get(\"sky\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "742451eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of Embedding matrix : (4689, 50)\n",
      "Embedding Vector for word \"hi\" : \n",
      " [-0.54312998  0.34426999  0.27125001  1.04869998 -1.16419995 -1.27219999\n",
      "  0.35780999 -0.56527001 -0.29879001  0.85179001  0.52222002 -0.0019718\n",
      " -0.46434999  0.033631    0.048367    0.78762001  0.075995    0.51577002\n",
      "  0.34777999  0.53802001  0.28299001 -0.1313     -0.073753    0.42614001\n",
      "  0.030954   -0.55032998 -0.99789    -0.28946999  0.30517    -1.11940002\n",
      "  1.29569995  0.91165     0.32222     0.93405002 -0.34152001 -0.62712997\n",
      " -0.092165    0.50901002  0.29203999 -0.20122001  0.19614001 -0.45881999\n",
      "  1.1099     -0.68737     1.57239997 -0.10446     0.23593999 -0.56594002\n",
      "  0.43676001  0.98092997]\n"
     ]
    }
   ],
   "source": [
    "#We now associate each token ID in our data set vocabulary to the corresponding embedding in Glove\n",
    "#If the word is not available, then embedding will be all zeros.\n",
    "\n",
    "#Matrix with 1 row for each word in the data set vocubulary and 50 features\n",
    "\n",
    "vocab_len = len(spam_tokenizer.word_index) + 1\n",
    "\n",
    "embedding_matrix = np.zeros((vocab_len, 50))\n",
    "\n",
    "for word, id in spam_tokenizer.word_index.items():  \n",
    "    try:\n",
    "        embedding_vector = glove_dict.get(word) \n",
    "        if embedding_vector is not None:         \n",
    "            embedding_matrix[id] = embedding_vector\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "print(\"Size of Embedding matrix :\", embedding_matrix.shape)\n",
    "print(\"Embedding Vector for word \\\"hi\\\" : \\n\", embedding_matrix[spam_tokenizer.word_index.get(\"hi\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4d2ea4a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'to': 1,\n",
       " 'you': 2,\n",
       " 'a': 3,\n",
       " 'i': 4,\n",
       " 'call': 5,\n",
       " 'the': 6,\n",
       " 'your': 7,\n",
       " 'u': 8,\n",
       " 'for': 9,\n",
       " 'is': 10,\n",
       " 'and': 11,\n",
       " 'now': 12,\n",
       " 'free': 13,\n",
       " 'or': 14,\n",
       " '2': 15,\n",
       " 'have': 16,\n",
       " 'in': 17,\n",
       " 'on': 18,\n",
       " 'of': 19,\n",
       " 'txt': 20,\n",
       " 'ur': 21,\n",
       " '4': 22,\n",
       " 'with': 23,\n",
       " 'are': 24,\n",
       " 'me': 25,\n",
       " 'from': 26,\n",
       " 'my': 27,\n",
       " 'text': 28,\n",
       " 'just': 29,\n",
       " 'get': 30,\n",
       " 'stop': 31,\n",
       " 'this': 32,\n",
       " 'mobile': 33,\n",
       " 'reply': 34,\n",
       " 'that': 35,\n",
       " 'claim': 36,\n",
       " 'no': 37,\n",
       " 'be': 38,\n",
       " 'so': 39,\n",
       " 'it': 40,\n",
       " 'only': 41,\n",
       " 'out': 42,\n",
       " 'our': 43,\n",
       " 'www': 44,\n",
       " 'will': 45,\n",
       " 'prize': 46,\n",
       " 'we': 47,\n",
       " 'send': 48,\n",
       " 'not': 49,\n",
       " 'new': 50,\n",
       " 'if': 51,\n",
       " 'can': 52,\n",
       " 'cash': 53,\n",
       " 'at': 54,\n",
       " 'do': 55,\n",
       " 'but': 56,\n",
       " 'won': 57,\n",
       " '1': 58,\n",
       " 'all': 59,\n",
       " '150p': 60,\n",
       " 'week': 61,\n",
       " \"i'm\": 62,\n",
       " 't': 63,\n",
       " 'msg': 64,\n",
       " 'nokia': 65,\n",
       " 'go': 66,\n",
       " 'uk': 67,\n",
       " 'win': 68,\n",
       " 'please': 69,\n",
       " 'as': 70,\n",
       " 'been': 71,\n",
       " 'know': 72,\n",
       " 'urgent': 73,\n",
       " 'tone': 74,\n",
       " 'like': 75,\n",
       " 'when': 76,\n",
       " 'who': 77,\n",
       " 'up': 78,\n",
       " 'contact': 79,\n",
       " 'com': 80,\n",
       " 'want': 81,\n",
       " 'by': 82,\n",
       " 'service': 83,\n",
       " '50': 84,\n",
       " 'co': 85,\n",
       " '16': 86,\n",
       " 'time': 87,\n",
       " 'am': 88,\n",
       " 'day': 89,\n",
       " 'what': 90,\n",
       " '18': 91,\n",
       " 'phone': 92,\n",
       " 'customer': 93,\n",
       " 'per': 94,\n",
       " 'guaranteed': 95,\n",
       " 'there': 96,\n",
       " 'min': 97,\n",
       " 'how': 98,\n",
       " 'c': 99,\n",
       " 'has': 100,\n",
       " 'good': 101,\n",
       " 'got': 102,\n",
       " 'gt': 103,\n",
       " 'r': 104,\n",
       " 'ok': 105,\n",
       " 'then': 106,\n",
       " 'chat': 107,\n",
       " 'lt': 108,\n",
       " 'cs': 109,\n",
       " 'more': 110,\n",
       " 'message': 111,\n",
       " 'hi': 112,\n",
       " 'draw': 113,\n",
       " 'need': 114,\n",
       " 'see': 115,\n",
       " 'an': 116,\n",
       " 'sms': 117,\n",
       " 'every': 118,\n",
       " 'â£1': 119,\n",
       " 'dear': 120,\n",
       " 'great': 121,\n",
       " 'was': 122,\n",
       " 'love': 123,\n",
       " 'find': 124,\n",
       " 'awarded': 125,\n",
       " 'yes': 126,\n",
       " 'back': 127,\n",
       " 'latest': 128,\n",
       " '3': 129,\n",
       " 'today': 130,\n",
       " 'mins': 131,\n",
       " 'take': 132,\n",
       " 'line': 133,\n",
       " 'sorry': 134,\n",
       " 'any': 135,\n",
       " 'camera': 136,\n",
       " 'number': 137,\n",
       " 'receive': 138,\n",
       " 'â£1000': 139,\n",
       " '150ppm': 140,\n",
       " 'going': 141,\n",
       " 'po': 142,\n",
       " 'box': 143,\n",
       " 'its': 144,\n",
       " 'live': 145,\n",
       " 'holiday': 146,\n",
       " 'wk': 147,\n",
       " 'he': 148,\n",
       " 'k': 149,\n",
       " 'video': 150,\n",
       " 'dont': 151,\n",
       " 'landline': 152,\n",
       " 'shows': 153,\n",
       " 'ringtone': 154,\n",
       " 'about': 155,\n",
       " 'rate': 156,\n",
       " 'still': 157,\n",
       " 'they': 158,\n",
       " 'tell': 159,\n",
       " 'apply': 160,\n",
       " 'come': 161,\n",
       " 'here': 162,\n",
       " 'code': 163,\n",
       " 'offer': 164,\n",
       " '000': 165,\n",
       " 'chance': 166,\n",
       " 'had': 167,\n",
       " \"don't\": 168,\n",
       " 'her': 169,\n",
       " 'award': 170,\n",
       " 'cost': 171,\n",
       " 'well': 172,\n",
       " '1st': 173,\n",
       " 'orange': 174,\n",
       " 'account': 175,\n",
       " 'hope': 176,\n",
       " 'special': 177,\n",
       " 'why': 178,\n",
       " 'make': 179,\n",
       " 'network': 180,\n",
       " 'over': 181,\n",
       " 'entry': 182,\n",
       " 'word': 183,\n",
       " 'miss': 184,\n",
       " 'tones': 185,\n",
       " 'one': 186,\n",
       " 'selected': 187,\n",
       " 'home': 188,\n",
       " 'think': 189,\n",
       " 'collection': 190,\n",
       " 'pls': 191,\n",
       " 'give': 192,\n",
       " 'mob': 193,\n",
       " \"i'll\": 194,\n",
       " 'weekly': 195,\n",
       " '10p': 196,\n",
       " '500': 197,\n",
       " 'â£100': 198,\n",
       " 'help': 199,\n",
       " 'n': 200,\n",
       " 'valid': 201,\n",
       " 'thanks': 202,\n",
       " 'b': 203,\n",
       " 'sent': 204,\n",
       " 'collect': 205,\n",
       " 'some': 206,\n",
       " 'e': 207,\n",
       " '2nd': 208,\n",
       " 'attempt': 209,\n",
       " 'waiting': 210,\n",
       " 'update': 211,\n",
       " 'national': 212,\n",
       " 'music': 213,\n",
       " 'where': 214,\n",
       " 'first': 215,\n",
       " 'meet': 216,\n",
       " 'delivery': 217,\n",
       " 'bonus': 218,\n",
       " '8007': 219,\n",
       " 'texts': 220,\n",
       " 'vouchers': 221,\n",
       " 'real': 222,\n",
       " 'http': 223,\n",
       " \"it's\": 224,\n",
       " 'say': 225,\n",
       " 'next': 226,\n",
       " 'way': 227,\n",
       " 'â£5000': 228,\n",
       " 'sae': 229,\n",
       " 'did': 230,\n",
       " 'night': 231,\n",
       " 'someone': 232,\n",
       " '5': 233,\n",
       " 'after': 234,\n",
       " 'colour': 235,\n",
       " 'â£500': 236,\n",
       " 'already': 237,\n",
       " 'play': 238,\n",
       " 'double': 239,\n",
       " 'â£2000': 240,\n",
       " 'too': 241,\n",
       " 's': 242,\n",
       " 'poly': 243,\n",
       " 'later': 244,\n",
       " 'name': 245,\n",
       " 'price': 246,\n",
       " 'gift': 247,\n",
       " 'club': 248,\n",
       " 'place': 249,\n",
       " 'games': 250,\n",
       " 'x': 251,\n",
       " 'much': 252,\n",
       " 'last': 253,\n",
       " 'babe': 254,\n",
       " 'trying': 255,\n",
       " 'friend': 256,\n",
       " '86688': 257,\n",
       " 'await': 258,\n",
       " 'end': 259,\n",
       " 'said': 260,\n",
       " 'buy': 261,\n",
       " 'unsubscribe': 262,\n",
       " 'guess': 263,\n",
       " '10': 264,\n",
       " 'bt': 265,\n",
       " \"c's\": 266,\n",
       " 'half': 267,\n",
       " 'work': 268,\n",
       " 'hey': 269,\n",
       " 'xxx': 270,\n",
       " 'best': 271,\n",
       " 'happy': 272,\n",
       " 'net': 273,\n",
       " '750': 274,\n",
       " 'pounds': 275,\n",
       " 'todays': 276,\n",
       " 'private': 277,\n",
       " 'land': 278,\n",
       " 'tried': 279,\n",
       " 'which': 280,\n",
       " 'dating': 281,\n",
       " 'join': 282,\n",
       " 'm': 283,\n",
       " 'opt': 284,\n",
       " 'top': 285,\n",
       " 'xmas': 286,\n",
       " 'services': 287,\n",
       " 'v': 288,\n",
       " 'calls': 289,\n",
       " 'cant': 290,\n",
       " 'row': 291,\n",
       " 'final': 292,\n",
       " 'even': 293,\n",
       " 'may': 294,\n",
       " 'keep': 295,\n",
       " '12hrs': 296,\n",
       " 'points': 297,\n",
       " 'expires': 298,\n",
       " 'auction': 299,\n",
       " 'messages': 300,\n",
       " '08000930705': 301,\n",
       " 'pobox': 302,\n",
       " 'd': 303,\n",
       " 'does': 304,\n",
       " 'done': 305,\n",
       " 'order': 306,\n",
       " 'voucher': 307,\n",
       " 'friends': 308,\n",
       " 'wanna': 309,\n",
       " 'winner': 310,\n",
       " 'us': 311,\n",
       " 'mobileupd8': 312,\n",
       " 'him': 313,\n",
       " 'could': 314,\n",
       " 'ltd': 315,\n",
       " 'sure': 316,\n",
       " 'statement': 317,\n",
       " 'identifier': 318,\n",
       " 'minutes': 319,\n",
       " 'camcorder': 320,\n",
       " 'tomorrow': 321,\n",
       " '100': 322,\n",
       " 'days': 323,\n",
       " 'enjoy': 324,\n",
       " 'â£3': 325,\n",
       " 'yours': 326,\n",
       " 'cos': 327,\n",
       " 'use': 328,\n",
       " 'always': 329,\n",
       " 'really': 330,\n",
       " 'again': 331,\n",
       " 'ask': 332,\n",
       " \"i've\": 333,\n",
       " 'sexy': 334,\n",
       " 'should': 335,\n",
       " 'month': 336,\n",
       " 'hot': 337,\n",
       " 'easy': 338,\n",
       " 'were': 339,\n",
       " 'suite342': 340,\n",
       " '2lands': 341,\n",
       " '08000839402': 342,\n",
       " 'very': 343,\n",
       " 'quiz': 344,\n",
       " 'worth': 345,\n",
       " 'money': 346,\n",
       " 'operator': 347,\n",
       " 'would': 348,\n",
       " 'important': 349,\n",
       " 'congratulations': 350,\n",
       " 'â£250': 351,\n",
       " 're': 352,\n",
       " 'ready': 353,\n",
       " 'info': 354,\n",
       " 'life': 355,\n",
       " 'content': 356,\n",
       " 'ã¼': 357,\n",
       " 'also': 358,\n",
       " 'lunch': 359,\n",
       " 'lor': 360,\n",
       " 'she': 361,\n",
       " 'late': 362,\n",
       " 'same': 363,\n",
       " 'tv': 364,\n",
       " 'pic': 365,\n",
       " 'care': 366,\n",
       " 'getting': 367,\n",
       " 'before': 368,\n",
       " 'looking': 369,\n",
       " 'wkly': 370,\n",
       " \"you're\": 371,\n",
       " 'anytime': 372,\n",
       " 'savamob': 373,\n",
       " 'pics': 374,\n",
       " 'freemsg': 375,\n",
       " 'nice': 376,\n",
       " 'â£2': 377,\n",
       " '03': 378,\n",
       " 'g': 379,\n",
       " '87066': 380,\n",
       " 'mates': 381,\n",
       " 'things': 382,\n",
       " 'down': 383,\n",
       " 'yet': 384,\n",
       " 'wait': 385,\n",
       " '6': 386,\n",
       " '11': 387,\n",
       " 'right': 388,\n",
       " '0800': 389,\n",
       " 'txts': 390,\n",
       " 'offers': 391,\n",
       " 'speak': 392,\n",
       " 'hello': 393,\n",
       " 'â£350': 394,\n",
       " '2003': 395,\n",
       " '800': 396,\n",
       " 'his': 397,\n",
       " 'caller': 398,\n",
       " 'ya': 399,\n",
       " 'off': 400,\n",
       " 'date': 401,\n",
       " 'rental': 402,\n",
       " 'phones': 403,\n",
       " 'mobiles': 404,\n",
       " 'tc': 405,\n",
       " '7': 406,\n",
       " 'part': 407,\n",
       " 'finish': 408,\n",
       " 'lol': 409,\n",
       " 'room': 410,\n",
       " 'yeah': 411,\n",
       " \"that's\": 412,\n",
       " 'charge': 413,\n",
       " 'weekend': 414,\n",
       " 'choose': 415,\n",
       " 'complimentary': 416,\n",
       " 'maybe': 417,\n",
       " 'call2optout': 418,\n",
       " 'ipod': 419,\n",
       " 'let': 420,\n",
       " 'being': 421,\n",
       " 'player': 422,\n",
       " 'ac': 423,\n",
       " 'charged': 424,\n",
       " 'them': 425,\n",
       " '04': 426,\n",
       " 'un': 427,\n",
       " 'redeemed': 428,\n",
       " 'reveal': 429,\n",
       " \"can't\": 430,\n",
       " 'eg': 431,\n",
       " 'news': 432,\n",
       " 'credit': 433,\n",
       " 'either': 434,\n",
       " 'reward': 435,\n",
       " 'luv': 436,\n",
       " 'wap': 437,\n",
       " 'yr': 438,\n",
       " 'valued': 439,\n",
       " 'im': 440,\n",
       " 'fancy': 441,\n",
       " 'book': 442,\n",
       " 'year': 443,\n",
       " 'game': 444,\n",
       " 'std': 445,\n",
       " 'start': 446,\n",
       " 'talk': 447,\n",
       " 'w1j6hl': 448,\n",
       " 'stuff': 449,\n",
       " 'motorola': 450,\n",
       " 'f': 451,\n",
       " 'fun': 452,\n",
       " 'world': 453,\n",
       " 'sex': 454,\n",
       " 'nothing': 455,\n",
       " 'long': 456,\n",
       " 'da': 457,\n",
       " 'guys': 458,\n",
       " 'pay': 459,\n",
       " 'hg': 460,\n",
       " 'oh': 461,\n",
       " 'gonna': 462,\n",
       " 'dogging': 463,\n",
       " 'man': 464,\n",
       " 'pick': 465,\n",
       " '00': 466,\n",
       " 'matches': 467,\n",
       " 'comp': 468,\n",
       " 'enter': 469,\n",
       " 'between': 470,\n",
       " 'shop': 471,\n",
       " 'many': 472,\n",
       " 'gr8': 473,\n",
       " 'each': 474,\n",
       " 'check': 475,\n",
       " 'try': 476,\n",
       " 'txting': 477,\n",
       " 'getzed': 478,\n",
       " 'ah': 479,\n",
       " 'ill': 480,\n",
       " 'baby': 481,\n",
       " 'feel': 482,\n",
       " 'lucky': 483,\n",
       " 'until': 484,\n",
       " 'pm': 485,\n",
       " 'told': 486,\n",
       " 'cool': 487,\n",
       " 'something': 488,\n",
       " 'amp': 489,\n",
       " 'â£10': 490,\n",
       " 'ntt': 491,\n",
       " 'details': 492,\n",
       " 'direct': 493,\n",
       " 'welcome': 494,\n",
       " 'congrats': 495,\n",
       " 'ldn': 496,\n",
       " 'ts': 497,\n",
       " 'morning': 498,\n",
       " 'answer': 499,\n",
       " 'unlimited': 500,\n",
       " 'del': 501,\n",
       " 'question': 502,\n",
       " 'ringtones': 503,\n",
       " 'custcare': 504,\n",
       " 'tonight': 505,\n",
       " 'hmv': 506,\n",
       " \"there's\": 507,\n",
       " 'representative': 508,\n",
       " 'secret': 509,\n",
       " 'admirer': 510,\n",
       " 'thinks': 511,\n",
       " 'balance': 512,\n",
       " 'currently': 513,\n",
       " 'person': 514,\n",
       " 'smile': 515,\n",
       " 'into': 516,\n",
       " 'reach': 517,\n",
       " 'charity': 518,\n",
       " 'msgs': 519,\n",
       " '11mths': 520,\n",
       " 'must': 521,\n",
       " 'car': 522,\n",
       " 'doing': 523,\n",
       " 'little': 524,\n",
       " 'around': 525,\n",
       " 'y': 526,\n",
       " 'class': 527,\n",
       " 'stay': 528,\n",
       " 'few': 529,\n",
       " 'anything': 530,\n",
       " 'shopping': 531,\n",
       " 'log': 532,\n",
       " 'while': 533,\n",
       " 'times': 534,\n",
       " 'â£800': 535,\n",
       " 'bit': 536,\n",
       " '150': 537,\n",
       " 'minute': 538,\n",
       " 'ldew': 539,\n",
       " 'â£200': 540,\n",
       " 'years': 541,\n",
       " 'weeks': 542,\n",
       " 'coming': 543,\n",
       " \"won't\": 544,\n",
       " 'bluetooth': 545,\n",
       " 'england': 546,\n",
       " 'credits': 547,\n",
       " 'once': 548,\n",
       " 'saturday': 549,\n",
       " 'â£150': 550,\n",
       " 'discount': 551,\n",
       " 'age16': 552,\n",
       " 'rates': 553,\n",
       " 'flag': 554,\n",
       " 'sunshine': 555,\n",
       " 'lot': 556,\n",
       " 'address': 557,\n",
       " '20p': 558,\n",
       " 'numbers': 559,\n",
       " 'comuk': 560,\n",
       " 'specially': 561,\n",
       " 'yup': 562,\n",
       " '02': 563,\n",
       " '06': 564,\n",
       " '20': 565,\n",
       " 'girl': 566,\n",
       " 'age': 567,\n",
       " '50p': 568,\n",
       " 'polys': 569,\n",
       " '25p': 570,\n",
       " \"t's\": 571,\n",
       " '2004': 572,\n",
       " 'mind': 573,\n",
       " 'cd': 574,\n",
       " 'no1': 575,\n",
       " 'terms': 576,\n",
       " '87077': 577,\n",
       " 'close': 578,\n",
       " 'leave': 579,\n",
       " 'area': 580,\n",
       " 'soon': 581,\n",
       " 'wat': 582,\n",
       " 'enough': 583,\n",
       " 'entered': 584,\n",
       " 'pa': 585,\n",
       " 'asked': 586,\n",
       " '0870': 587,\n",
       " 'shit': 588,\n",
       " '08712460324': 589,\n",
       " 'freephone': 590,\n",
       " 'digital': 591,\n",
       " 'within': 592,\n",
       " 'inc': 593,\n",
       " 'ip4': 594,\n",
       " '5we': 595,\n",
       " 'entitled': 596,\n",
       " 'jus': 597,\n",
       " 'sat': 598,\n",
       " 'information': 599,\n",
       " 'because': 600,\n",
       " 'sony': 601,\n",
       " 'rply': 602,\n",
       " 'match': 603,\n",
       " 'people': 604,\n",
       " 'ring': 605,\n",
       " 'sub': 606,\n",
       " 'rcvd': 607,\n",
       " 'sp': 608,\n",
       " 'hours': 609,\n",
       " 'summer': 610,\n",
       " 'evening': 611,\n",
       " 'thank': 612,\n",
       " 'haha': 613,\n",
       " 'll': 614,\n",
       " 'having': 615,\n",
       " 'look': 616,\n",
       " 'bed': 617,\n",
       " 'missing': 618,\n",
       " 'user': 619,\n",
       " 'thats': 620,\n",
       " 'calling': 621,\n",
       " 'another': 622,\n",
       " 'awaiting': 623,\n",
       " 'store': 624,\n",
       " 'ending': 625,\n",
       " '3030': 626,\n",
       " 'b4': 627,\n",
       " 'immediately': 628,\n",
       " '10am': 629,\n",
       " 'unsub': 630,\n",
       " 'biz': 631,\n",
       " '36504': 632,\n",
       " 'break': 633,\n",
       " 'gud': 634,\n",
       " 'yo': 635,\n",
       " 'dun': 636,\n",
       " 'lar': 637,\n",
       " 'ans': 638,\n",
       " 'invited': 639,\n",
       " 'went': 640,\n",
       " 'press': 641,\n",
       " '9': 642,\n",
       " 'bid': 643,\n",
       " 'big': 644,\n",
       " 'etc': 645,\n",
       " 'o2': 646,\n",
       " 'access': 647,\n",
       " 'open': 648,\n",
       " 'ever': 649,\n",
       " 'spree': 650,\n",
       " 'horny': 651,\n",
       " 'bx420': 652,\n",
       " \"you've\": 653,\n",
       " 'loyalty': 654,\n",
       " 'tenerife': 655,\n",
       " 'sk38xh': 656,\n",
       " 'yesterday': 657,\n",
       " 'sir': 658,\n",
       " '85023': 659,\n",
       " 'fine': 660,\n",
       " 'visit': 661,\n",
       " 'cup': 662,\n",
       " 'true': 663,\n",
       " '12': 664,\n",
       " 'plus': 665,\n",
       " 'extra': 666,\n",
       " 'frnd': 667,\n",
       " '62468': 668,\n",
       " 'job': 669,\n",
       " 'never': 670,\n",
       " 'better': 671,\n",
       " \"uk's\": 672,\n",
       " 'ha': 673,\n",
       " 'made': 674,\n",
       " 'hour': 675,\n",
       " 'fone': 676,\n",
       " 'card': 677,\n",
       " '1327': 678,\n",
       " 'croydon': 679,\n",
       " 'cr9': 680,\n",
       " '5wb': 681,\n",
       " 'onto': 682,\n",
       " 'fantastic': 683,\n",
       " 'yourself': 684,\n",
       " '82277': 685,\n",
       " 'logo': 686,\n",
       " 'dvd': 687,\n",
       " 'maximize': 688,\n",
       " '08718720201': 689,\n",
       " 'â£900': 690,\n",
       " 'costa': 691,\n",
       " 'sol': 692,\n",
       " 'forwarded': 693,\n",
       " '7pm': 694,\n",
       " 'asap': 695,\n",
       " 'girls': 696,\n",
       " 'zed': 697,\n",
       " 'txtauction': 698,\n",
       " '8': 699,\n",
       " 'â£400': 700,\n",
       " 'computer': 701,\n",
       " 'means': 702,\n",
       " 'though': 703,\n",
       " 'link': 704,\n",
       " 'thought': 705,\n",
       " 'ard': 706,\n",
       " 'prob': 707,\n",
       " 'lots': 708,\n",
       " 'driving': 709,\n",
       " 'change': 710,\n",
       " 'dat': 711,\n",
       " \"u've\": 712,\n",
       " 'might': 713,\n",
       " 'anyway': 714,\n",
       " 'liao': 715,\n",
       " 'replying': 716,\n",
       " 'callertune': 717,\n",
       " 'luck': 718,\n",
       " 'hard': 719,\n",
       " 'goto': 720,\n",
       " 'gay': 721,\n",
       " 'vary': 722,\n",
       " 'believe': 723,\n",
       " 'future': 724,\n",
       " 'bored': 725,\n",
       " 'pound': 726,\n",
       " 'arcade': 727,\n",
       " 'office': 728,\n",
       " 'sipix': 729,\n",
       " '28': 730,\n",
       " 'cum': 731,\n",
       " 'xx': 732,\n",
       " 'away': 733,\n",
       " 'these': 734,\n",
       " 'tncs': 735,\n",
       " 'lose': 736,\n",
       " 'wid': 737,\n",
       " 'pass': 738,\n",
       " '150pm': 739,\n",
       " 'announcement': 740,\n",
       " 'holder': 741,\n",
       " 'pc': 742,\n",
       " 'mail': 743,\n",
       " 'most': 744,\n",
       " 'dinner': 745,\n",
       " \"didn't\": 746,\n",
       " 'dis': 747,\n",
       " 'than': 748,\n",
       " 'handset': 749,\n",
       " 'tariffs': 750,\n",
       " 'available': 751,\n",
       " 'sky': 752,\n",
       " 'member': 753,\n",
       " 'pobox84': 754,\n",
       " '40gb': 755,\n",
       " 'w45wq': 756,\n",
       " 'norm150p': 757,\n",
       " 'save': 758,\n",
       " 'activate': 759,\n",
       " 'crazy': 760,\n",
       " 'town': 761,\n",
       " 'company': 762,\n",
       " 'standard': 763,\n",
       " 'inviting': 764,\n",
       " 'takes': 765,\n",
       " 'princess': 766,\n",
       " 'early': 767,\n",
       " 'show': 768,\n",
       " 'didnt': 769,\n",
       " 'wont': 770,\n",
       " 'vodafone': 771,\n",
       " 'other': 772,\n",
       " 'run': 773,\n",
       " 'thk': 774,\n",
       " 'questions': 775,\n",
       " 'fantasies': 776,\n",
       " '08707509020': 777,\n",
       " 'called': 778,\n",
       " 'urawinner': 779,\n",
       " 'missed': 780,\n",
       " 'heart': 781,\n",
       " 'hl': 782,\n",
       " 'arrive': 783,\n",
       " '08712300220': 784,\n",
       " 'flights': 785,\n",
       " 'eve': 786,\n",
       " '86021': 787,\n",
       " 'login': 788,\n",
       " 'cc': 789,\n",
       " '09050090044': 790,\n",
       " 'toclaim': 791,\n",
       " 'pobox334': 792,\n",
       " 'stockport': 793,\n",
       " 'costâ£1': 794,\n",
       " 'max10mins': 795,\n",
       " 'bank': 796,\n",
       " '300': 797,\n",
       " 'polyphonic': 798,\n",
       " 'subscription': 799,\n",
       " 'alert': 800,\n",
       " 'local': 801,\n",
       " 'euro2004': 802,\n",
       " 'hit': 803,\n",
       " 'song': 804,\n",
       " '3510i': 805,\n",
       " '80488': 806,\n",
       " '2optout': 807,\n",
       " 'giving': 808,\n",
       " 'lovable': 809,\n",
       " 'problem': 810,\n",
       " 'remember': 811,\n",
       " 'straight': 812,\n",
       " 'full': 813,\n",
       " 'click': 814,\n",
       " 'themob': 815,\n",
       " 'coffee': 816,\n",
       " 'alright': 817,\n",
       " 'thanx': 818,\n",
       " '2day': 819,\n",
       " 'callsâ£1': 820,\n",
       " 'pain': 821,\n",
       " 'thing': 822,\n",
       " 'correct': 823,\n",
       " '80062': 824,\n",
       " 'following': 825,\n",
       " 'felt': 826,\n",
       " \"'\": 827,\n",
       " 'watching': 828,\n",
       " 'high': 829,\n",
       " 'download': 830,\n",
       " 'brother': 831,\n",
       " 'comes': 832,\n",
       " 'forgot': 833,\n",
       " 'pobox36504w45wq': 834,\n",
       " 'king': 835,\n",
       " 'busy': 836,\n",
       " 'finally': 837,\n",
       " 'knows': 838,\n",
       " '60p': 839,\n",
       " 'hear': 840,\n",
       " 'cds': 841,\n",
       " 'fantasy': 842,\n",
       " 'cancel': 843,\n",
       " '3g': 844,\n",
       " 'videophones': 845,\n",
       " 'videochat': 846,\n",
       " 'java': 847,\n",
       " 'dload': 848,\n",
       " 'noline': 849,\n",
       " 'rentl': 850,\n",
       " 'ave': 851,\n",
       " 'post': 852,\n",
       " 'tickets': 853,\n",
       " 'records': 854,\n",
       " 'two': 855,\n",
       " 'sport': 856,\n",
       " 'xchat': 857,\n",
       " 'birthday': 858,\n",
       " 'street': 859,\n",
       " 'december': 860,\n",
       " 'worry': 861,\n",
       " 'everyone': 862,\n",
       " 'inclusive': 863,\n",
       " 'wish': 864,\n",
       " \"he's\": 865,\n",
       " 'sonyericsson': 866,\n",
       " 'linerental': 867,\n",
       " 'eerie': 868,\n",
       " 'wen': 869,\n",
       " 'partner': 870,\n",
       " 'christmas': 871,\n",
       " 'dream': 872,\n",
       " 'starts': 873,\n",
       " '1x150p': 874,\n",
       " 'id': 875,\n",
       " '05': 876,\n",
       " 'remove': 877,\n",
       " 'optout': 878,\n",
       " '25': 879,\n",
       " 'men': 880,\n",
       " 'feeling': 881,\n",
       " 'weekends': 882,\n",
       " 'movie': 883,\n",
       " 'cut': 884,\n",
       " 'official': 885,\n",
       " 'selection': 886,\n",
       " 'afternoon': 887,\n",
       " 'boytoy': 888,\n",
       " 'joined': 889,\n",
       " 'sleeping': 890,\n",
       " 'eat': 891,\n",
       " 'tomo': 892,\n",
       " 'months': 893,\n",
       " 'decimal': 894,\n",
       " 'cheap': 895,\n",
       " 'leh': 896,\n",
       " 'put': 897,\n",
       " 'sending': 898,\n",
       " 'hmmm': 899,\n",
       " 'touch': 900,\n",
       " 'since': 901,\n",
       " 'ends': 902,\n",
       " 'sleep': 903,\n",
       " 'bath': 904,\n",
       " 'starting': 905,\n",
       " 'house': 906,\n",
       " 'meant': 907,\n",
       " 'surprise': 908,\n",
       " 'ec2a': 909,\n",
       " 'mp3': 910,\n",
       " '83355': 911,\n",
       " 'revealed': 912,\n",
       " 'voda': 913,\n",
       " 'quoting': 914,\n",
       " '434': 915,\n",
       " 'locations': 916,\n",
       " 'singles': 917,\n",
       " 'trip': 918,\n",
       " 'contacted': 919,\n",
       " 'spook': 920,\n",
       " 'kiss': 921,\n",
       " 'kind': 922,\n",
       " '87131': 923,\n",
       " \"week's\": 924,\n",
       " 'competition': 925,\n",
       " '21': 926,\n",
       " 'bill': 927,\n",
       " 'their': 928,\n",
       " 'bad': 929,\n",
       " 'kept': 930,\n",
       " 'daily': 931,\n",
       " 'kick': 932,\n",
       " 'children': 933,\n",
       " 'plan': 934,\n",
       " '08718727870': 935,\n",
       " \"we'll\": 936,\n",
       " 'conditions': 937,\n",
       " 'lost': 938,\n",
       " 'picked': 939,\n",
       " 'listen': 940,\n",
       " 'self': 941,\n",
       " 'whole': 942,\n",
       " 'coz': 943,\n",
       " 'biggest': 944,\n",
       " 'adult': 945,\n",
       " 'fixed': 946,\n",
       " 'dunno': 947,\n",
       " 'abt': 948,\n",
       " 'flirt': 949,\n",
       " 'everything': 950,\n",
       " 'met': 951,\n",
       " 'else': 952,\n",
       " 'ãœ': 953,\n",
       " 'oso': 954,\n",
       " 'registered': 955,\n",
       " 'subscriber': 956,\n",
       " 'delivered': 957,\n",
       " 'review': 958,\n",
       " \"''\": 959,\n",
       " 'askd': 960,\n",
       " 'request': 961,\n",
       " 'set': 962,\n",
       " 'copy': 963,\n",
       " 'story': 964,\n",
       " 'cust': 965,\n",
       " 'somebody': 966,\n",
       " 'rude': 967,\n",
       " '2nite': 968,\n",
       " 'mr': 969,\n",
       " 'bloomberg': 970,\n",
       " 'center': 971,\n",
       " 'lesson': 972,\n",
       " 'loads': 973,\n",
       " 'bring': 974,\n",
       " 'meeting': 975,\n",
       " '0': 976,\n",
       " 'purchase': 977,\n",
       " '24': 978,\n",
       " '542': 979,\n",
       " 'via': 980,\n",
       " '85': 981,\n",
       " '09061221066': 982,\n",
       " 'fromm': 983,\n",
       " 'cause': 984,\n",
       " '4u': 985,\n",
       " 'com1win150ppmx3age16': 986,\n",
       " 'paris': 987,\n",
       " 'situation': 988,\n",
       " 'ibiza': 989,\n",
       " '3mins': 990,\n",
       " 'wc1n3xx': 991,\n",
       " 'vip': 992,\n",
       " 'hav': 993,\n",
       " '81151': 994,\n",
       " '4t': 995,\n",
       " 'ref': 996,\n",
       " 'started': 997,\n",
       " 'msgrcvdhg': 998,\n",
       " '5000': 999,\n",
       " 'tcs': 1000,\n",
       " ...}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_tokenizer.word_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34bdc629",
   "metadata": {},
   "source": [
    "## Build the Spam Model with Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "edc608b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Embedding-Layer (Embedding)  (None, 100, 50)          234450    \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 256)               314368    \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 256)               0         \n",
      "                                                                 \n",
      " Output-Layer (Dense)        (None, 2)                 514       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 549,332\n",
      "Trainable params: 549,332\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Create a model\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from keras.layers import LSTM,Dense\n",
    "\n",
    "#Setup Hyper-Parameters for building the model\n",
    "NUM_CLASSES=2\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "model.add(keras.layers.Embedding(vocab_len,\n",
    "                                 50, \n",
    "                                 name=\"Embedding-Layer\",\n",
    "                                 weights=[embedding_matrix],\n",
    "                                 input_length=MAX_SEQUENCE_LENGTH,\n",
    "                                 trainable=True))\n",
    "\n",
    "#Add LSTM Layer\n",
    "model.add(LSTM(256))\n",
    "model.add(keras.layers.Flatten())\n",
    "\n",
    "model.add(keras.layers.Dense(NUM_CLASSES,\n",
    "                             name='Output-Layer',\n",
    "                             activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42349101",
   "metadata": {},
   "source": [
    "## Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f73ba11f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Progress:\n",
      "------------------------------------\n",
      "Epoch 1/10\n",
      "4/4 [==============================] - 5s 784ms/step - loss: 0.6388 - accuracy: 0.6344 - val_loss: 0.4181 - val_accuracy: 0.8542\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 3s 638ms/step - loss: 0.3250 - accuracy: 0.9062 - val_loss: 0.1809 - val_accuracy: 0.9375\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 3s 634ms/step - loss: 0.2523 - accuracy: 0.9052 - val_loss: 0.2931 - val_accuracy: 0.9000\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 3s 644ms/step - loss: 0.2440 - accuracy: 0.9219 - val_loss: 0.1531 - val_accuracy: 0.9542\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 2s 612ms/step - loss: 0.1639 - accuracy: 0.9406 - val_loss: 0.1540 - val_accuracy: 0.9500\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 3s 632ms/step - loss: 0.2070 - accuracy: 0.9229 - val_loss: 0.1358 - val_accuracy: 0.9708\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 3s 655ms/step - loss: 0.1482 - accuracy: 0.9510 - val_loss: 0.1304 - val_accuracy: 0.9708\n",
      "Epoch 8/10\n",
      "4/4 [==============================] - 3s 711ms/step - loss: 0.1579 - accuracy: 0.9417 - val_loss: 0.1622 - val_accuracy: 0.9375\n",
      "Epoch 9/10\n",
      "4/4 [==============================] - 3s 681ms/step - loss: 0.1744 - accuracy: 0.9333 - val_loss: 0.1099 - val_accuracy: 0.9583\n",
      "Epoch 10/10\n",
      "4/4 [==============================] - 3s 745ms/step - loss: 0.1156 - accuracy: 0.9573 - val_loss: 0.1118 - val_accuracy: 0.9667\n",
      "\n",
      "Evaluation against Test Dataset :\n",
      "------------------------------------\n",
      "10/10 [==============================] - 1s 70ms/step - loss: 0.1203 - accuracy: 0.9600\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.12025237083435059, 0.9599999785423279]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Make it verbose so we can see the progress\n",
    "VERBOSE=1\n",
    "\n",
    "#Setup Hyper Parameters for training\n",
    "BATCH_SIZE=256\n",
    "EPOCHS=10\n",
    "VALIDATION_SPLIT=0.2\n",
    "\n",
    "print(\"\\nTraining Progress:\\n------------------------------------\")\n",
    "\n",
    "history=model.fit(X_train,\n",
    "          Y_train,\n",
    "          batch_size=BATCH_SIZE,\n",
    "          epochs=EPOCHS,\n",
    "          verbose=VERBOSE,\n",
    "          validation_split=VALIDATION_SPLIT)\n",
    "\n",
    "print(\"\\nEvaluation against Test Dataset :\\n------------------------------------\")\n",
    "model.evaluate(X_test,Y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcfc263f",
   "metadata": {},
   "source": [
    "## Predicting Spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f983ebfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 44ms/step\n",
      "Prediction Output: [1 0]\n",
      "Prediction Classes are  ['spam' 'ham']\n"
     ]
    }
   ],
   "source": [
    "# Two input strings to predict\n",
    "input_str=[\"enter the free auction link to get a free 2000 dollors gift\",\n",
    "            \"Do not call me again\"]\n",
    "\n",
    "#Convert to sequence using the same tokenizer as training\n",
    "input_seq = spam_tokenizer.texts_to_sequences(input_str)\n",
    "#Pad the input\n",
    "input_padded = pad_sequences(input_seq, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "#Predict using model\n",
    "prediction=np.argmax( model.predict(input_padded), axis=1 )\n",
    "print(\"Prediction Output:\" , prediction)\n",
    "\n",
    "#Print prediction classes\n",
    "print(\"Prediction Classes are \", label_encoder.inverse_transform(prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ce7410",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
